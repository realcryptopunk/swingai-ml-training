{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üèåÔ∏è SwingAI ML Training Pipeline\n",
        "**3 models for iOS golf swing analysis**\n",
        "\n",
        "| Model | Task | Output |\n",
        "|---|---|---|\n",
        "| Shaft Segmentation | Instance Seg | Shaft mask ‚Üí angle extraction |\n",
        "| Club Head Detector | Object Det | Club head bbox ‚Üí speed calc |\n",
        "| Phase Classifier | Classification | P1-P8 swing phase |\n",
        "\n",
        "**Runtime:** ~2 hours on A100 | **Output:** 3x `.mlpackage` CoreML models\n",
        "\n",
        "‚ö†Ô∏è **Set Runtime to GPU A100:** Runtime ‚Üí Change runtime type ‚Üí A100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================\n",
        "# CELL 1: Install dependencies\n",
        "# ============================================\n",
        "!pip install -q ultralytics roboflow coremltools\n",
        "\n",
        "import torch\n",
        "print(f'PyTorch: {torch.__version__}')\n",
        "print(f'CUDA: {torch.cuda.is_available()}')\n",
        "if torch.cuda.is_available():\n",
        "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
        "    print(f'VRAM: {torch.cuda.get_device_properties(0).total_mem / 1e9:.1f} GB')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================\n",
        "# CELL 2: Set your Roboflow API key\n",
        "# ============================================\n",
        "# Get your free API key at: https://app.roboflow.com/settings/api\n",
        "ROBOFLOW_API_KEY = \"YOUR_API_KEY_HERE\"  # <-- PASTE YOUR KEY"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## üîß Model 1: Shaft Segmentation\n",
        "**Datasets:** Segmentation Batch 13 (9.6K) + Golf Segmentation (3.2K) + Golf-Swing-Analyzer-DTL (1.5K)\n",
        "\n",
        "**Output:** Pixel mask of club shaft ‚Üí extract angle with cv2.fitLine()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================\n",
        "# CELL 3: Download shaft segmentation datasets\n",
        "# ============================================\n",
        "from roboflow import Roboflow\n",
        "import os, shutil\n",
        "\n",
        "rf = Roboflow(api_key=ROBOFLOW_API_KEY)\n",
        "\n",
        "# Dataset 1: Segmentation Batch 13 (9.6K images, shaft/arm/body masks)\n",
        "print('üì• Downloading Segmentation Batch 13...')\n",
        "ds1 = rf.workspace('fp-srwrm').project('segmentation-batch-13-sequence').version(2).download('yolov8', location='/content/shaft_ds1')\n",
        "\n",
        "# Dataset 2: Golf Segmentation (3.2K images, hand/head/shaft)\n",
        "print('üì• Downloading Golf Segmentation...')\n",
        "try:\n",
        "    ds2 = rf.workspace('golf-bpbfr').project('golf-segmentation-oocvp').version(1).download('yolov8', location='/content/shaft_ds2')\n",
        "except:\n",
        "    print('‚ö†Ô∏è Golf Segmentation dataset not accessible ‚Äî continuing with primary dataset')\n",
        "    ds2 = None\n",
        "\n",
        "# Dataset 3: Golf-Swing-Analyzer-DTL (1.5K images, hand/head/shaft)\n",
        "print('üì• Downloading Golf-Swing-Analyzer-DTL...')\n",
        "try:\n",
        "    ds3 = rf.workspace('bosharluke').project('golf-swing-analyzer-dtl').version(1).download('yolov8', location='/content/shaft_ds3')\n",
        "except:\n",
        "    print('‚ö†Ô∏è DTL dataset not accessible ‚Äî continuing with available datasets')\n",
        "    ds3 = None\n",
        "\n",
        "print('‚úÖ Shaft datasets downloaded')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================\n",
        "# CELL 4: Merge shaft datasets\n",
        "# ============================================\n",
        "import yaml, glob\n",
        "\n",
        "# Use primary dataset as base\n",
        "SHAFT_DATA = '/content/shaft_ds1'\n",
        "\n",
        "# Merge additional datasets if available\n",
        "for extra_ds in ['/content/shaft_ds2', '/content/shaft_ds3']:\n",
        "    if os.path.exists(extra_ds):\n",
        "        for split in ['train', 'valid', 'test']:\n",
        "            src_imgs = os.path.join(extra_ds, split, 'images')\n",
        "            src_lbls = os.path.join(extra_ds, split, 'labels')\n",
        "            dst_imgs = os.path.join(SHAFT_DATA, split, 'images')\n",
        "            dst_lbls = os.path.join(SHAFT_DATA, split, 'labels')\n",
        "            if os.path.exists(src_imgs):\n",
        "                for f in glob.glob(os.path.join(src_imgs, '*')):\n",
        "                    shutil.copy2(f, dst_imgs)\n",
        "                for f in glob.glob(os.path.join(src_lbls, '*')):\n",
        "                    shutil.copy2(f, dst_lbls)\n",
        "        print(f'‚úÖ Merged {extra_ds}')\n",
        "\n",
        "# Count total images\n",
        "train_imgs = len(glob.glob(os.path.join(SHAFT_DATA, 'train', 'images', '*')))\n",
        "val_imgs = len(glob.glob(os.path.join(SHAFT_DATA, 'valid', 'images', '*')))\n",
        "print(f'üìä Shaft dataset: {train_imgs} train + {val_imgs} val images')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================\n",
        "# CELL 5: Train Shaft Segmentation Model\n",
        "# ============================================\n",
        "from ultralytics import YOLO\n",
        "\n",
        "print('üèãÔ∏è Training Shaft Segmentation (YOLOv8m-seg)...')\n",
        "print('‚è±Ô∏è Estimated time: ~60-90 min on A100')\n",
        "\n",
        "shaft_model = YOLO('yolov8m-seg.pt')\n",
        "\n",
        "shaft_results = shaft_model.train(\n",
        "    data=os.path.join(SHAFT_DATA, 'data.yaml'),\n",
        "    epochs=100,\n",
        "    imgsz=640,\n",
        "    batch=32,\n",
        "    device=0,\n",
        "    project='/content/runs',\n",
        "    name='shaft_seg',\n",
        "    patience=15,       # early stopping\n",
        "    augment=True,\n",
        "    mosaic=1.0,\n",
        "    flipud=0.5,\n",
        "    fliplr=0.5,\n",
        "    degrees=15,\n",
        "    scale=0.5,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print('‚úÖ Shaft segmentation training complete!')\n",
        "print(f'Best model: /content/runs/shaft_seg/weights/best.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## üéØ Model 2: Club Head Detector\n",
        "**Datasets:** Golf Driver Tracker (2.7K) + SwingMentor Golf (8.5K) + Golf VFA (2.8K)\n",
        "\n",
        "**Output:** Club head bounding box ‚Üí track position ‚Üí calculate speed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================\n",
        "# CELL 6: Download club head datasets\n",
        "# ============================================\n",
        "print('üì• Downloading Golf Driver Tracker...')\n",
        "try:\n",
        "    ch1 = rf.workspace('salo-levy').project('golf-driver-tracker').version(3).download('yolov8', location='/content/clubhead_ds1')\n",
        "except:\n",
        "    print('‚ö†Ô∏è Golf Driver Tracker not accessible')\n",
        "\n",
        "print('üì• Downloading SwingMentor Golf...')\n",
        "try:\n",
        "    ch2 = rf.workspace('swingmentor').project('golf-0okbs').version(9).download('yolov8', location='/content/clubhead_ds2')\n",
        "except:\n",
        "    print('‚ö†Ô∏è SwingMentor not accessible')\n",
        "\n",
        "print('üì• Downloading Golf VFA...')\n",
        "try:\n",
        "    ch3 = rf.workspace('trungam').project('golf-vfa').version(2).download('yolov8', location='/content/clubhead_ds3')\n",
        "except:\n",
        "    print('‚ö†Ô∏è Golf VFA not accessible')\n",
        "\n",
        "print('‚úÖ Club head datasets downloaded')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================\n",
        "# CELL 7: Merge club head datasets\n",
        "# ============================================\n",
        "CLUBHEAD_DATA = '/content/clubhead_ds1'\n",
        "\n",
        "# Use first available dataset as base, merge others\n",
        "base_found = False\n",
        "for ds_path in ['/content/clubhead_ds1', '/content/clubhead_ds2', '/content/clubhead_ds3']:\n",
        "    if os.path.exists(ds_path):\n",
        "        if not base_found:\n",
        "            CLUBHEAD_DATA = ds_path\n",
        "            base_found = True\n",
        "            continue\n",
        "        for split in ['train', 'valid', 'test']:\n",
        "            src_imgs = os.path.join(ds_path, split, 'images')\n",
        "            src_lbls = os.path.join(ds_path, split, 'labels')\n",
        "            dst_imgs = os.path.join(CLUBHEAD_DATA, split, 'images')\n",
        "            dst_lbls = os.path.join(CLUBHEAD_DATA, split, 'labels')\n",
        "            if os.path.exists(src_imgs):\n",
        "                os.makedirs(dst_imgs, exist_ok=True)\n",
        "                os.makedirs(dst_lbls, exist_ok=True)\n",
        "                for f in glob.glob(os.path.join(src_imgs, '*')):\n",
        "                    shutil.copy2(f, dst_imgs)\n",
        "                for f in glob.glob(os.path.join(src_lbls, '*')):\n",
        "                    shutil.copy2(f, dst_lbls)\n",
        "        print(f'‚úÖ Merged {ds_path}')\n",
        "\n",
        "train_imgs = len(glob.glob(os.path.join(CLUBHEAD_DATA, 'train', 'images', '*')))\n",
        "val_imgs = len(glob.glob(os.path.join(CLUBHEAD_DATA, 'valid', 'images', '*')))\n",
        "print(f'üìä Club head dataset: {train_imgs} train + {val_imgs} val images')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================\n",
        "# CELL 8: Train Club Head Detector\n",
        "# ============================================\n",
        "print('üèãÔ∏è Training Club Head Detector (YOLOv8m)...')\n",
        "print('‚è±Ô∏è Estimated time: ~45-60 min on A100')\n",
        "\n",
        "clubhead_model = YOLO('yolov8m.pt')\n",
        "\n",
        "clubhead_results = clubhead_model.train(\n",
        "    data=os.path.join(CLUBHEAD_DATA, 'data.yaml'),\n",
        "    epochs=100,\n",
        "    imgsz=640,\n",
        "    batch=32,\n",
        "    device=0,\n",
        "    project='/content/runs',\n",
        "    name='clubhead_det',\n",
        "    patience=15,\n",
        "    augment=True,\n",
        "    mosaic=1.0,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print('‚úÖ Club head detector training complete!')\n",
        "print(f'Best model: /content/runs/clubhead_det/weights/best.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## üìä Model 3: Phase Classifier (SwingNet Boost)\n",
        "**Datasets:** Golf_Swing_Phases_8 (4.6K) + golf swing 2 (6.8K)\n",
        "\n",
        "**Output:** P1-P8 classification per frame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================\n",
        "# CELL 9: Download phase classifier datasets\n",
        "# ============================================\n",
        "print('üì• Downloading Golf_Swing_Phases_8...')\n",
        "try:\n",
        "    pc1 = rf.workspace('container-number-dectection').project('golf_swing_phases_8-mrk0i').version(1).download('folder', location='/content/phase_ds1')\n",
        "except:\n",
        "    print('‚ö†Ô∏è Phases dataset not accessible')\n",
        "\n",
        "print('üì• Downloading golf swing 2...')\n",
        "try:\n",
        "    pc2 = rf.workspace('pose-7amrv').project('golf-swing-2-bycnn').version(1).download('folder', location='/content/phase_ds2')\n",
        "except:\n",
        "    print('‚ö†Ô∏è Golf swing 2 not accessible')\n",
        "\n",
        "print('‚úÖ Phase classifier datasets downloaded')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================\n",
        "# CELL 10: Train Phase Classifier\n",
        "# ============================================\n",
        "print('üèãÔ∏è Training Phase Classifier (YOLOv8m-cls)...')\n",
        "print('‚è±Ô∏è Estimated time: ~30-45 min on A100')\n",
        "\n",
        "# Find the dataset that downloaded successfully\n",
        "PHASE_DATA = None\n",
        "for p in ['/content/phase_ds1', '/content/phase_ds2']:\n",
        "    if os.path.exists(p):\n",
        "        PHASE_DATA = p\n",
        "        break\n",
        "\n",
        "if PHASE_DATA:\n",
        "    phase_model = YOLO('yolov8m-cls.pt')\n",
        "\n",
        "    phase_results = phase_model.train(\n",
        "        data=PHASE_DATA,\n",
        "        epochs=100,\n",
        "        imgsz=224,\n",
        "        batch=64,\n",
        "        device=0,\n",
        "        project='/content/runs',\n",
        "        name='phase_cls',\n",
        "        patience=15,\n",
        "        verbose=True\n",
        "    )\n",
        "    print('‚úÖ Phase classifier training complete!')\n",
        "    print(f'Best model: /content/runs/phase_cls/weights/best.pt')\n",
        "else:\n",
        "    print('‚ùå No phase dataset available')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## üì± Export to CoreML for iOS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================\n",
        "# CELL 11: Export all models to CoreML\n",
        "# ============================================\n",
        "import glob\n",
        "\n",
        "models_to_export = {\n",
        "    'shaft_seg': '/content/runs/shaft_seg/weights/best.pt',\n",
        "    'clubhead_det': '/content/runs/clubhead_det/weights/best.pt',\n",
        "    'phase_cls': '/content/runs/phase_cls/weights/best.pt',\n",
        "}\n",
        "\n",
        "exported = []\n",
        "for name, path in models_to_export.items():\n",
        "    if os.path.exists(path):\n",
        "        print(f'üì± Exporting {name} to CoreML...')\n",
        "        model = YOLO(path)\n",
        "        model.export(format='coreml', nms=True)\n",
        "        # Find the exported mlpackage\n",
        "        mlpkg = path.replace('.pt', '.mlpackage')\n",
        "        if os.path.exists(mlpkg):\n",
        "            exported.append((name, mlpkg))\n",
        "            print(f'  ‚úÖ {name} ‚Üí {mlpkg}')\n",
        "    else:\n",
        "        print(f'  ‚è≠Ô∏è Skipping {name} (not trained)')\n",
        "\n",
        "print(f'\\nüéâ Exported {len(exported)} CoreML models!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================\n",
        "# CELL 12: Package & download all models\n",
        "# ============================================\n",
        "!mkdir -p /content/swingai_models\n",
        "\n",
        "# Copy all CoreML models to one folder\n",
        "for name, mlpkg in exported:\n",
        "    dst = f'/content/swingai_models/{name}.mlpackage'\n",
        "    if os.path.exists(mlpkg):\n",
        "        shutil.copytree(mlpkg, dst, dirs_exist_ok=True)\n",
        "\n",
        "# Also copy the .pt files for future fine-tuning\n",
        "for name, path in models_to_export.items():\n",
        "    if os.path.exists(path):\n",
        "        shutil.copy2(path, f'/content/swingai_models/{name}.pt')\n",
        "\n",
        "# Zip everything\n",
        "!cd /content && zip -r swingai_models.zip swingai_models/\n",
        "\n",
        "print('\\nüì¶ All models packaged!')\n",
        "print('Download: /content/swingai_models.zip')\n",
        "print('\\nModels included:')\n",
        "!ls -lh /content/swingai_models/\n",
        "\n",
        "# Auto-download in Colab\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download('/content/swingai_models.zip')\n",
        "except:\n",
        "    print('\\nüí° Download manually from the file browser on the left')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## üìä Training Results Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================\n",
        "# CELL 13: Print results summary\n",
        "# ============================================\n",
        "print('=' * 60)\n",
        "print('üèåÔ∏è SwingAI Training Results')\n",
        "print('=' * 60)\n",
        "\n",
        "for name, path in models_to_export.items():\n",
        "    results_csv = path.replace('weights/best.pt', 'results.csv')\n",
        "    if os.path.exists(results_csv):\n",
        "        import pandas as pd\n",
        "        df = pd.read_csv(results_csv)\n",
        "        df.columns = df.columns.str.strip()\n",
        "        print(f'\\nüìä {name}:')\n",
        "        if 'metrics/mAP50(B)' in df.columns:\n",
        "            best_map = df['metrics/mAP50(B)'].max()\n",
        "            print(f'   Best mAP50: {best_map:.3f}')\n",
        "        if 'metrics/mAP50-95(B)' in df.columns:\n",
        "            best_map95 = df['metrics/mAP50-95(B)'].max()\n",
        "            print(f'   Best mAP50-95: {best_map95:.3f}')\n",
        "        if 'metrics/accuracy_top1' in df.columns:\n",
        "            best_acc = df['metrics/accuracy_top1'].max()\n",
        "            print(f'   Best Top-1 Accuracy: {best_acc:.3f}')\n",
        "        print(f'   Epochs trained: {len(df)}')\n",
        "\n",
        "print('\\n' + '=' * 60)\n",
        "print('\\nüöÄ Next steps:')\n",
        "print('1. Download swingai_models.zip')\n",
        "print('2. Unzip and drag .mlpackage files into Xcode')\n",
        "print('3. Add inference code to SwingAI app')\n",
        "print('4. Ship it! üèåÔ∏è‚Äç‚ôÇÔ∏è')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}